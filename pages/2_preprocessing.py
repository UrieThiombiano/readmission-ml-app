import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
import joblib
from scipy import sparse
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
import time

st.set_page_config(page_title="Pr√©processing", page_icon="‚öôÔ∏è", layout="wide")
st.title("‚öôÔ∏è Pr√©processing ‚Äî Pr√©paration des Donn√©es")

# CSS personnalis√© avec animations
st.markdown("""
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .warning-card {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        transition: all 0.3s ease;
    }
    .success-card {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        transition: all 0.3s ease;
    }
    .navigation-buttons {
        display: flex;
        gap: 1rem;
        margin-top: 2rem;
    }
    .fade-in {
        animation: fadeIn 0.8s ease-in;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea, #764ba2);
    }
    .param-section {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
        transition: all 0.3s ease;
    }
    .param-section:hover {
        background: #e9ecef;
    }
</style>
""", unsafe_allow_html=True)

# --- 0) V√©rifications initiales ---
if "df_raw" not in st.session_state:
    st.error("üì≠ Aucun dataset en m√©moire. Retournez √† la page **Upload**.")
    st.stop()

df = st.session_state["df_raw"].copy()

# Header informatif avec animation
st.markdown("""
<div class="fade-in" style="background-color: #e8f4fd; padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem;">
    <h3 style="margin:0; color: #155724;">üéØ Objectif du Pr√©processing</h3>
    <p style="margin:0.5rem 0 0 0;">Transformer votre dataset en format <strong>100% num√©rique</strong> pr√™t pour l'entra√Ænement ML</p>
</div>
""", unsafe_allow_html=True)

# --- 1) Analyse exploratoire initiale ---
st.subheader("üìä Analyse Exploratoire Initiale")

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric("Lignes", f"{df.shape[0]:,}")
    st.markdown('</div>', unsafe_allow_html=True)
with col2:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric("Colonnes", df.shape[1])
    st.markdown('</div>', unsafe_allow_html=True)
with col3:
    missing_total = df.isna().sum().sum()
    missing_pct = (missing_total / (df.shape[0] * df.shape[1])) * 100
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric("Donn√©es manquantes", f"{missing_pct:.1f}%")
    st.markdown('</div>', unsafe_allow_html=True)
with col4:
    numeric_cols = df.select_dtypes(include=['number']).shape[1]
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric("Colonnes num√©riques", numeric_cols)
    st.markdown('</div>', unsafe_allow_html=True)

# Visualisations rapides avec tabs anim√©s
tab1, tab2, tab3 = st.tabs(["üìã Aper√ßu donn√©es", "üìà Types de donn√©es", "‚ö†Ô∏è Donn√©es manquantes"])

with tab1:
    st.dataframe(df.head(10), use_container_width=True, height=300)

with tab2:
    dtype_counts = df.dtypes.astype(str).value_counts()
    fig_dtype = px.pie(values=dtype_counts.values, names=dtype_counts.index,
                       title="R√©partition des types de donn√©es")
    st.plotly_chart(fig_dtype, use_container_width=True)

with tab3:
    missing_data = df.isna().sum()
    missing_data = missing_data[missing_data > 0].sort_values(ascending=True)
    if len(missing_data) > 0:
        fig_missing = px.bar(x=missing_data.values, y=missing_data.index, orientation='h',
                             title="Donn√©es manquantes par colonne",
                             labels={'x': 'Nombre de valeurs manquantes', 'y': 'Colonnes'})
        st.plotly_chart(fig_missing, use_container_width=True)
    else:
        st.success("‚úÖ Aucune donn√©e manquante d√©tect√©e")

# --- 2) Configuration du pr√©processing ---
st.subheader("‚öôÔ∏è Configuration du Pr√©processing")

# S√©lection de la cible
cols = df.columns.tolist()
target = st.selectbox(
    "**Colonne cible** (variable √† pr√©dire)",
    options=cols,
    index=(cols.index("readmitted_num") if "readmitted_num" in cols else
           cols.index("readmission") if "readmission" in cols else
           cols.index("target") if "target" in cols else 0),
    help="S√©lectionnez la variable que vous souhaitez pr√©dire"
)

# Affichage info cible
if target:
    target_info = df[target].value_counts()
    st.write(f"**Distribution de la cible `{target}`:**")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Valeurs uniques", target_info.shape[0])
    with col2:
        st.metric("Valeur majoritaire", f"{target_info.index[0]} ({target_info.iloc[0] / len(df) * 100:.1f}%)")
    with col3:
        if target_info.shape[0] == 2:
            imbalance_ratio = min(target_info) / max(target_info)
            st.metric("Ratio d√©s√©quilibre", f"{imbalance_ratio:.2f}")

# Options de pr√©traitement
st.markdown("**Options de pr√©traitement:**")
c1, c2, c3 = st.columns(3)
with c1:
    test_size = st.slider("Taille du jeu de test", 0.1, 0.4, 0.2, 0.05)
    drop_dups = st.checkbox("Supprimer les doublons", value=True)
with c2:
    random_state = st.number_input("Random state", 0, 9999, 42)
    scale_numeric = st.checkbox("Standardiser les num√©riques", value=True)
with c3:
    min_freq = st.number_input("Fr√©quence min. cat√©gories", min_value=0.0, max_value=0.2, value=0.01, step=0.01,
                               help="Regroupe les cat√©gories rares")
    handle_unknown = st.selectbox("Gestion nouvelles cat√©gories",
                                  options=["infrequent_if_exist", "ignore"], index=0)

# Gestion des doublons
if drop_dups:
    before = len(df)
    df = df.drop_duplicates()
    after = len(df)
    if after < before:
        st.info(f"üóëÔ∏è Doublons supprim√©s : {before - after} ligne(s)")

# --- 3) S√©lection des caract√©ristiques ---
st.subheader("üéØ S√©lection des Caract√©ristiques")

y = df[target]
X = df.drop(columns=[target])

# D√©tection automatique
detected_num = X.select_dtypes(include=np.number).columns.tolist()
detected_cat = X.select_dtypes(include=['object', 'category']).columns.tolist()

col1, col2 = st.columns(2)
with col1:
    st.markdown("**Colonnes Num√©riques**")
    num_cols = st.multiselect(
        "S√©lectionnez les colonnes num√©riques",
        options=X.columns.tolist(),
        default=detected_num,
        help="Variables continues ou discr√®tes"
    )

with col2:
    st.markdown("**Colonnes Cat√©gorielles**")
    cat_cols = st.multiselect(
        "S√©lectionnez les colonnes cat√©gorielles",
        options=[c for c in X.columns if c not in num_cols],
        default=detected_cat,
        help="Variables qualitatives (seront encod√©es)"
    )

# Colonnes ignor√©es
missing = [c for c in X.columns if c not in num_cols + cat_cols]
if missing:
    st.warning(f"‚ö†Ô∏è Colonnes ignor√©es (ni num√©riques ni cat√©gorielles) : {', '.join(missing)}")

# --- 4) Pipelines de pr√©traitement ---
st.subheader("üîß Pipelines de Transformation")

# Pipelines
num_pipeline = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    *([("scaler", StandardScaler())] if scale_numeric else [])
])

cat_pipeline = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(
        handle_unknown=handle_unknown,
        sparse_output=True,
        min_frequency=min_freq if handle_unknown == "infrequent_if_exist" else None
    ))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", num_pipeline, num_cols),
        ("cat", cat_pipeline, cat_cols),
    ],
    remainder="drop"
)

# --- 5) Configuration du GridSearch ---
st.subheader("üéõÔ∏è Configuration du GridSearch")

with st.expander("‚öôÔ∏è Param√®tres avanc√©s du GridSearch", expanded=True):
    st.markdown("""
    <div class="param-section">
    <h4>üîß Param√®tres de recherche</h4>
    """, unsafe_allow_html=True)

    gs_col1, gs_col2, gs_col3 = st.columns(3)

    with gs_col1:
        cv_folds = st.slider("Nombre de folds CV", 3, 10, 5,
                             help="Nombre de folds pour la validation crois√©e")
        scoring_metric = st.selectbox("M√©trique d'√©valuation",
                                      ["roc_auc", "accuracy", "f1", "precision", "recall"],
                                      index=0,
                                      help="M√©trique utilis√©e pour √©valuer les mod√®les")

    with gs_col2:
        n_jobs = st.selectbox("Parall√©lisation",
                              [1, 2, 4, -1],
                              index=3,
                              format_func=lambda x: f"{x} core(s)" if x != -1 else "Tous les cores",
                              help="Nombre de jobs parall√®les (-1 = tous les cores)")
        verbosity = st.selectbox("Verbosite",
                                 [0, 1, 2, 3],
                                 index=0,
                                 help="Niveau de d√©tail des logs (0 = silencieux)")

    with gs_col3:
        refit = st.checkbox("Refit automatique", value=True,
                            help="Re-entra√Æne le meilleur mod√®le sur toutes les donn√©es")
        enable_cache = st.checkbox("Cache GridSearch", value=True,
                                   help="Active le cache pour acc√©l√©rer les recherches")

    st.markdown("</div>", unsafe_allow_html=True)

# --- 6) Application du pr√©processing ---
st.subheader("üöÄ Application des Transformations")

if st.button("üî® Appliquer le Pr√©processing", type="primary", use_container_width=True):

    # Barre de progression avec animation
    progress_bar = st.progress(0)
    status_text = st.empty()

    steps = [
        "Initialisation...",
        "Split des donn√©es...",
        "Pr√©processing num√©rique...",
        "Encodage cat√©goriel...",
        "Finalisation..."
    ]

    for i, step in enumerate(steps):
        status_text.text(f"üîÑ {step}")
        progress_bar.progress((i + 1) / len(steps))
        time.sleep(0.3)  # Animation fluide

    with st.spinner("Application des transformations..."):
        # Split des donn√©es
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state,
            stratify=y if y.nunique() == 2 else None
        )

        # Fit et transform
        X_train_t = preprocessor.fit_transform(X_train)
        X_test_t = preprocessor.transform(X_test)

        # Feature names
        try:
            feature_names = preprocessor.get_feature_names_out()
        except:
            feature_names = np.array([f"feature_{i}" for i in range(X_train_t.shape[1])])

        # Sauvegarde en session avec param√®tres GridSearch
        st.session_state.update({
            "preprocessor": preprocessor,
            "feature_names": feature_names,
            "X_train": X_train_t,
            "X_test": X_test_t,
            "y_train": y_train,
            "y_test": y_test,
            "preprocessing_applied": True,
            "gridsearch_params": {
                "cv_folds": cv_folds,
                "scoring_metric": scoring_metric,
                "n_jobs": n_jobs,
                "verbosity": verbosity,
                "refit": refit,
                "enable_cache": enable_cache
            }
        })

    # Affichage des r√©sultats avec animation
    status_text.text("‚úÖ Pr√©processing termin√© !")
    progress_bar.empty()

    st.balloons()  # Animation de c√©l√©bration

    # M√©triques finales
    st.markdown("### üìä M√©triques Finales du Pr√©processing")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Features finales", X_train_t.shape[1])
    with col2:
        st.metric("Train size", f"{X_train_t.shape[0]:,}")
    with col3:
        st.metric("Test size", f"{X_test_t.shape[0]:,}")
    with col4:
        if sparse.issparse(X_train_t):
            density = (X_train_t.nnz / (X_train_t.shape[0] * X_train_t.shape[1])) * 100
        else:
            non_zero_count = np.count_nonzero(X_train_t)
            density = (non_zero_count / (X_train_t.shape[0] * X_train_t.shape[1])) * 100
        st.metric("Densit√© matrice", f"{density:.1f}%")

    # Aper√ßu des features
    with st.expander("üëÅÔ∏è Aper√ßu des Features Transform√©es", expanded=False):
        try:
            if sparse.issparse(X_train_t):
                X_train_df = pd.DataFrame.sparse.from_spmatrix(X_train_t, columns=feature_names)
            else:
                X_train_df = pd.DataFrame(X_train_t, columns=feature_names)
            st.dataframe(X_train_df.iloc[:8, :12], use_container_width=True)

            st.write(f"**Type de matrice :** {'Sparse' if sparse.issparse(X_train_t) else 'Dense'}")
            st.write(f"**Format :** {X_train_t.shape[0]} √ó {X_train_t.shape[1]}")

        except Exception as e:
            st.error(f"Erreur lors de la cr√©ation de l'aper√ßu : {e}")
            st.info("Aper√ßu non disponible pour les grandes matrices")

    # Informations sur l'encodage
    with st.expander("üîç D√©tails de l'Encodage", expanded=False):
        try:
            num_features = len(num_cols)
            cat_features = 0
            for col in cat_cols:
                try:
                    unique_vals = X[col].nunique()
                    cat_features += unique_vals
                except:
                    cat_features += 1

            st.write(f"**Features num√©riques originales :** {num_features}")
            st.write(f"**Features cat√©gorielles originales :** {len(cat_cols)}")
            st.write(f"**Features totales apr√®s encodage :** {len(feature_names)}")
            st.write(f"**Facteur d'expansion :** {len(feature_names) / (num_features + len(cat_cols)):.1f}x")

        except Exception as e:
            st.write("Informations d'encodage non disponibles")

    # Sauvegarde optionnelle
    st.markdown("### üíæ Sauvegarde")
    if st.button("üíæ Sauvegarder les Art√©facts", use_container_width=True):
        with st.spinner("Sauvegarde en cours..."):
            Path("models").mkdir(exist_ok=True)
            joblib.dump(preprocessor, "models/preprocessor.pkl")
            joblib.dump({"feature_names": feature_names}, "models/meta.pkl")

            # Sauvegarde des param√®tres GridSearch
            gridsearch_config = {
                "cv_folds": cv_folds,
                "scoring_metric": scoring_metric,
                "n_jobs": n_jobs,
                "verbosity": verbosity,
                "refit": refit
            }
            joblib.dump(gridsearch_config, "models/gridsearch_config.pkl")

            try:
                if sparse.issparse(X_train_t):
                    sparse.save_npz("models/X_train.npz", X_train_t)
                    sparse.save_npz("models/X_test.npz", X_test_t)
                else:
                    np.save("models/X_train.npy", X_train_t)
                    np.save("models/X_test.npy", X_test_t)

                pd.Series(y_train).to_csv("models/y_train.csv", index=False)
                pd.Series(y_test).to_csv("models/y_test.csv", index=False)
                st.success("‚úÖ Donn√©es transform√©es sauvegard√©es dans `models/`")
            except Exception as e:
                st.warning(f"Donn√©es transform√©es non sauvegard√©es : {e}")

            st.success("Art√©facts sauvegard√©s dans `models/`")

# --- 7) Navigation vers la page suivante ---
st.markdown("---")
st.subheader("üéØ Navigation")

# V√©rifier si le pr√©processing a √©t√© fait dans cette session
preprocessing_applied = st.session_state.get("preprocessing_applied", False)

if preprocessing_applied:
    st.success("‚úÖ Pr√©processing termin√© ! Vous pouvez maintenant passer √† la mod√©lisation.")

    col1, col2 = st.columns([1, 1])

    with col1:
        if st.button("üöÄ Passer √† la Mod√©lisation", type="primary", use_container_width=True):
            try:
                # Animation de transition
                with st.spinner("Chargement de la page de mod√©lisation..."):
                    time.sleep(1)
                    st.switch_page("pages/3_Mod√©lisation_et_GridSearch.py")
            except Exception as e:
                st.error(f"Erreur de navigation : {e}")

    with col2:
        if st.button("üîÑ Recommencer le Pr√©processing", type="secondary", use_container_width=True):
            # R√©initialiser les variables de session
            keys_to_remove = ["preprocessor", "feature_names", "X_train", "X_test", "y_train", "y_test",
                              "preprocessing_applied", "gridsearch_params"]
            for key in keys_to_remove:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

else:
    st.info(
        "üëÜ Cliquez sur **'Appliquer le Pr√©processing'** pour pr√©parer vos donn√©es avant de passer √† la mod√©lisation.")

# --- 8) Instructions suppl√©mentaires ---
with st.expander("üìã Instructions importantes", expanded=False):
    st.markdown("""
    **Pour une mod√©lisation r√©ussie :**

    1. **S√©lectionnez la bonne variable cible** - doit √™tre binaire (0/1) pour la classification
    2. **V√©rifiez les types de colonnes** - num√©riques vs cat√©gorielles
    3. **Configurez le GridSearch** - param√®tres de recherche avanc√©s
    4. **Appliquez le pr√©processing** - cliquez sur le bouton bleu ci-dessus
    5. **Passez √† la mod√©lisation** - une fois le pr√©processing termin√©

    **Conseils GridSearch :**
    - **CV Folds** : 5-10 folds pour un bon compromis performance/stabilit√©
    - **M√©trique** : ROC-AUC recommand√©e pour les probl√®mes d√©s√©quilibr√©s
    - **Parall√©lisation** : Utilisez tous les cores (-1) pour acc√©l√©rer
    - **Cache** : Activez le cache pour les recherches r√©p√©t√©es
    """)